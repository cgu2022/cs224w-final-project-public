{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling, negative_sampling\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines LightGCN model\n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, course_ada_emb=None, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users, self.num_items = num_users, num_items\n",
    "        self.embedding_dim, self.K = embedding_dim, K\n",
    "        self.add_self_loops = add_self_loops\n",
    "        self.cours_ada_emb = course_ada_emb\n",
    "        ada_emb_len = course_ada_emb.shape[-1]\n",
    "        \n",
    "        # pre_diffusion embedding will be used for regularization computing\n",
    "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "        self.emb_transform = nn.Sequential(nn.Linear(in_features=ada_emb_len, out_features=embedding_dim),\n",
    "                                           nn.GELU(),\n",
    "                                           nn.LayerNorm(embedding_dim),\n",
    "                                           nn.Linear(in_features=embedding_dim, out_features=embedding_dim),\n",
    "                                           nn.GELU(),\n",
    "                                           nn.LayerNorm(embedding_dim))\n",
    "        self.score_mat = nn.Parameter(torch.eye(embedding_dim),requires_grad=False)\n",
    "        \n",
    "        # embedding after multi-scale diffusion\n",
    "        # this will be used to give final recommendation/compute brp loss\n",
    "        self.users_emb_final = None\n",
    "        self.items_emb_final = None\n",
    "        \n",
    "\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: SparseTensor, weight=1):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        edge_index_norm = gcn_norm(edge_index, add_self_loops=self.add_self_loops)\n",
    "        \n",
    "        course_ada_emb = self.emb_transform(self.cours_ada_emb)\n",
    "        course_emb = course_ada_emb * weight + self.items_emb.weight\n",
    "\n",
    "        emb_0 = torch.cat([self.users_emb.weight, course_emb]) # E^0\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # multi-scale diffusion\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "        \n",
    "        self.users_emb_final = users_emb_final\n",
    "        self.items_emb_final = items_emb_final\n",
    "        # rating_mat = torch.matmul(users_emb_final, items_emb_final.T)\n",
    "        # returns the embedding of both the original and after multiscale diffusion\n",
    "        \n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final,  self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j: Tensor) -> Tensor:\n",
    "        return x_j\n",
    "\n",
    "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "        # computes \\tilde{A} @ x\n",
    "        return matmul(adj_t, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: LightGCN = torch.load('LightGCN/lightgcn_12_10.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_planned_courses.json') as f:\n",
    "    planned_courses = json.load(f)\n",
    "course_counter = {}\n",
    "\n",
    "# Iterating through each student's data to count enrollments and courses, excluding 'Unplanned'\n",
    "for student, quarters in planned_courses.items():\n",
    "    for quarter, courses in quarters.items():\n",
    "        if (quarter != 'None'):\n",
    "            # Counting course frequency\n",
    "            for course in courses:\n",
    "                if course== 'RESTRICTED':\n",
    "                    continue\n",
    "                if not (course in course_counter):\n",
    "                    course_counter[course] = 1\n",
    "                else:\n",
    "                    course_counter[course] += 1  \n",
    "                    \n",
    "# course_counter\n",
    "min_enrollments_thre = 4\n",
    "course_count_df = pd.DataFrame(course_counter.items(), columns=['Course', 'Enrollments'])\n",
    "course_count_df = course_count_df.drop(index=course_count_df[course_count_df.Enrollments < min_enrollments_thre].index)\n",
    "selected_courses = list(course_count_df.Course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of real users: 1895\n",
      "# of courses: 1518\n",
      "# of edges: 27086\n"
     ]
    }
   ],
   "source": [
    "userIds = {}\n",
    "courseIds = {}\n",
    "numEdges = 0\n",
    "min_courses_thre = 4\n",
    "\n",
    "# clean up data, create userIds and courseIds\n",
    "num_course_each_student = []\n",
    "Ids = []\n",
    "\n",
    "for user in list(planned_courses.keys()):\n",
    "    \n",
    "    # Pt.1 we count the total amount of courses each user already took\n",
    "    # and we get rid of the users with only a few course pinned\n",
    "    num = 0\n",
    "    for quarter in planned_courses[user]:\n",
    "        num += len(planned_courses[user][quarter])\n",
    "    \n",
    "    if num < min_courses_thre:\n",
    "        del planned_courses[user]\n",
    "        continue\n",
    "    else:\n",
    "        userIds[user] = len(userIds)\n",
    "    \n",
    "    #Pt.2 build the userIds and CourseIds dict\n",
    "    for quarter in planned_courses[user]:\n",
    "        numEdges += len(planned_courses[user][quarter])\n",
    "        for course in planned_courses[user][quarter]:\n",
    "            if course == 'RESTRICTED' or (course not in selected_courses):\n",
    "                numEdges -= 1\n",
    "                continue\n",
    "            if (course not in courseIds) :\n",
    "                courseIds[course] = len(courseIds)\n",
    "    Ids.append(len(userIds))\n",
    "    num_course_each_student.append(num)\n",
    "\n",
    "#The course' IDs will be followed after the user's IDs\n",
    "\n",
    "for item in courseIds:\n",
    "    courseIds[item] += len(userIds)\n",
    "\n",
    "print('# of real users:', len(userIds))\n",
    "print('# of courses:', len(courseIds))\n",
    "print('# of edges:', numEdges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create edge index, get num users and courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edge_index\n",
    "j = 0\n",
    "edge_index = torch.zeros((2, numEdges), dtype=int)\n",
    "train_edge_index = []\n",
    "val_edge_index_sup = []\n",
    "\n",
    "for user in planned_courses:\n",
    "    user_edge_index = []\n",
    "    for quarter in planned_courses[user]:\n",
    "        for course in planned_courses[user][quarter]:\n",
    "            if (course== 'RESTRICTED') or (course not in selected_courses):\n",
    "                continue\n",
    "            edge_index[0][j] = userIds[user]\n",
    "            edge_index[1][j] = courseIds[course]\n",
    "            user_edge_index.append((userIds[user], courseIds[course]))\n",
    "            j += 1\n",
    "            \n",
    "    # Here we split \n",
    "    user_num_courses = len(user_edge_index)\n",
    "    user_train_indices = random.sample([i for i in range(user_num_courses)], k=int(0.8*user_num_courses))\n",
    "    user_val_indices = list(set([i for i in range(user_num_courses)]) - set(user_train_indices))\n",
    "    train_edge_index += [user_edge_index[i] for i in user_train_indices]\n",
    "    val_edge_index_sup += [user_edge_index[i] for i in user_val_indices]\n",
    "    \n",
    "train_edge_index = torch.tensor(train_edge_index).T\n",
    "val_edge_index_sup = torch.tensor(val_edge_index_sup).T\n",
    "val_edge_index_msg = train_edge_index\n",
    "\n",
    "num_users, num_courses = len(userIds), len(courseIds)\n",
    "numNodes = num_users + num_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get N_u\n",
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "user_pos_items = get_user_positive_items(edge_index)\n",
    "id_to_course = {v: k for k, v in courseIds.items()}\n",
    "\n",
    "def make_predictions(user, num_recs, only_new=True):\n",
    "    e_u = model.users_emb_final[user]\n",
    "    scores = model.items_emb_final @ e_u\n",
    "\n",
    "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
    "    indices = [index.item() for index in indices]\n",
    "    \n",
    "    print(f\"Here are classes user {user} has already taken:\")\n",
    "    for index in user_pos_items[user]:\n",
    "        print(id_to_course[index])\n",
    "    print()\n",
    "    \n",
    "    print(f'Here are the top recommended courses{\" (* means already taken)\" if not only_new else \"\"}:')\n",
    "    i = 0\n",
    "    not_yet_taken = 0\n",
    "    while not_yet_taken < num_recs:\n",
    "        if not only_new or indices[i]+num_users not in user_pos_items[user]:\n",
    "            print(f\"{id_to_course[indices[i]+num_users]} {'(*)' if indices[i]+num_users in user_pos_items[user] else ''}\")\n",
    "        if indices[i]+num_users not in user_pos_items[user]:\n",
    "            not_yet_taken += 1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_user_with_classes(classes):\n",
    "    classes = set(classes)\n",
    "    for user in user_pos_items:\n",
    "        user_classes = set({id_to_course[id] for id in user_pos_items[user]})\n",
    "        if classes.issubset(user_classes):\n",
    "            print(user, user_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 {'CS109', 'ME108', 'CS103', 'JAPAN82N', 'PHYSWELL103', 'ME248', 'EMED124', 'PHYSICS41', 'CME100', 'CS106B', 'COLLEGE101', 'CS12SI', 'PWR1RB', 'CS129', 'STATS216', 'CME102', 'ME298', 'STATS203', 'DATASCI112', 'EMED127', 'CS107', 'PSYCH15N', 'ME30', 'ENGR14', 'BIO81', 'CS111', 'CS106A', 'CS131', 'STATS200', 'ME1', 'COLLEGE102', 'CS11SI', 'CS124'}\n"
     ]
    }
   ],
   "source": [
    "find_user_with_classes([\"CS109\", \"ME30\", \"BIO81\", \"CS11SI\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final cell: make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are classes user 480 has already taken:\n",
      "CME100\n",
      "COLLEGE101\n",
      "CS106A\n",
      "ME1\n",
      "COLLEGE102\n",
      "CS106B\n",
      "ME30\n",
      "PHYSICS41\n",
      "CS107\n",
      "ENGR14\n",
      "JAPAN82N\n",
      "PWR1RB\n",
      "BIO81\n",
      "CS109\n",
      "CS111\n",
      "CS11SI\n",
      "CME102\n",
      "CS103\n",
      "CS124\n",
      "CS129\n",
      "CS12SI\n",
      "CS131\n",
      "DATASCI112\n",
      "EMED124\n",
      "EMED127\n",
      "ME298\n",
      "PHYSWELL103\n",
      "PSYCH15N\n",
      "STATS200\n",
      "STATS203\n",
      "STATS216\n",
      "ME108\n",
      "ME248\n",
      "\n",
      "Here are the top recommended courses:\n",
      "CS107E \n",
      "PHYSICS43 \n",
      "DESIGN172 \n",
      "UAR101J \n",
      "MATH51 \n",
      "COLLEGE112 \n",
      "MATH104 \n",
      "CS161 \n",
      "CME192 \n",
      "CLASSICS84 \n",
      "FRENLANG1 \n",
      "ECON1 \n",
      "MATH53 \n",
      "ME210 \n",
      "PHYSICS41E \n"
     ]
    }
   ],
   "source": [
    "USER_ID = 480 #115, 675, 208\n",
    "NUM_RECS = 15\n",
    "\n",
    "make_predictions(USER_ID, NUM_RECS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "224W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
