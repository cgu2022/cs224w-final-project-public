{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)  # None means show all rows\n",
    "pd.set_option('display.max_columns', None)  # None means show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4154\n",
      "dict_keys(['description', 'subject', 'gers', 'units', 'code', 'days', 'titleSearch', 'title', 'quartersOffered'])\n"
     ]
    }
   ],
   "source": [
    "with open('new_course_metadata.json') as f:\n",
    "    course_metadata = json.load(f)\n",
    "\n",
    "# Open the file for reading\n",
    "with open('embeddings64_2023-12-09.pkl', 'rb') as f:\n",
    "    # Unpickle the embeddings\n",
    "    course_embeddings = pickle.load(f)\n",
    "\n",
    "courses = list(course_embeddings.keys()) # We use the keys from `embeddings` and not course_metadata because course_metadata has some `phantom courses` (courses that don't have metadata) \n",
    "print(len(courses))\n",
    "print(course_metadata['CS224V'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conversational Virtual Assistants with Deep Learning'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_metadata['CS224V']['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Course Subject Distrubtion - FULL DIMENSION SIZE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = [course_metadata[course]['subject'] for course in courses]\n",
    "\n",
    "\n",
    "subjects = []\n",
    "embeddings_list = []\n",
    "titles = []\n",
    "for course in courses:\n",
    "    subject = course_metadata[course]['subject']\n",
    "    title = course_metadata[course]['title']\n",
    "    embeddings_list.append(course_embeddings[course]['embedding'][0]['embedding'])\n",
    "    subjects.append(subject)\n",
    "    titles.append(title)\n",
    "\n",
    "subjects_counter = Counter(subjects)\n",
    "print(\"Number of unique subjects:\", len(subjects_counter))\n",
    "subjects_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Course Subject Distribution - REDUCED DIMENSION SIZE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique subjects: 179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'CS': 227,\n",
       "         'PWR': 145,\n",
       "         'HISTORY': 145,\n",
       "         'MUSIC': 128,\n",
       "         'ENGLISH': 110,\n",
       "         'CEE': 103,\n",
       "         'EE': 95,\n",
       "         'POLISCI': 90,\n",
       "         'MS&E': 83,\n",
       "         'BIO': 83,\n",
       "         'PHIL': 80,\n",
       "         'MATH': 79,\n",
       "         'EARTHSYS': 75,\n",
       "         'CLASSICS': 74,\n",
       "         'PSYCH': 70,\n",
       "         'EDUC': 68,\n",
       "         'ME': 65,\n",
       "         'ECON': 62,\n",
       "         'SOC': 57,\n",
       "         'PHYSICS': 57,\n",
       "         'HUMBIO': 53,\n",
       "         'ENGR': 53,\n",
       "         'SPECLANG': 52,\n",
       "         'CHINLANG': 49,\n",
       "         'ARTSTUDI': 48,\n",
       "         'TAPS': 46,\n",
       "         'CSRE': 45,\n",
       "         'PHYSWELL': 45,\n",
       "         'FEMGEN': 44,\n",
       "         'INTNLREL': 43,\n",
       "         'BIOE': 42,\n",
       "         'STATS': 41,\n",
       "         'COMM': 40,\n",
       "         'PUBLPOL': 39,\n",
       "         'ANTHRO': 36,\n",
       "         'AA': 35,\n",
       "         'CHEM': 35,\n",
       "         'ARTHIST': 35,\n",
       "         'COMPLIT': 34,\n",
       "         'UAR': 34,\n",
       "         'AMSTUD': 34,\n",
       "         'PSYC': 33,\n",
       "         'URBANST': 31,\n",
       "         'INTLPOL': 31,\n",
       "         'DESIGN': 31,\n",
       "         'AMELANG': 28,\n",
       "         'MED': 28,\n",
       "         'LINGUIST': 27,\n",
       "         'RELIGST': 26,\n",
       "         'SUSTAIN': 25,\n",
       "         'WELLNESS': 25,\n",
       "         'MATSCI': 24,\n",
       "         'CME': 24,\n",
       "         'OSPPARIS': 24,\n",
       "         'SPANLANG': 23,\n",
       "         'SYMSYS': 23,\n",
       "         'OSPFLOR': 23,\n",
       "         'ILAC': 23,\n",
       "         'DANCE': 22,\n",
       "         'FILMEDIA': 21,\n",
       "         'ENERGY': 21,\n",
       "         'ESS': 21,\n",
       "         'AFRICAAM': 21,\n",
       "         'LAW': 21,\n",
       "         'ESF': 20,\n",
       "         'ETHICSOC': 20,\n",
       "         'GEOLSCI': 19,\n",
       "         'OSPMADRD': 19,\n",
       "         'EPS': 18,\n",
       "         'OSPOXFRD': 18,\n",
       "         'ARCHLGY': 18,\n",
       "         'OCEANS': 17,\n",
       "         'GEOPHYS': 17,\n",
       "         'EMED': 16,\n",
       "         'SLAVLANG': 16,\n",
       "         'NATIVEAM': 15,\n",
       "         'JAPANLNG': 14,\n",
       "         'STS': 14,\n",
       "         'THINK': 14,\n",
       "         'FRENCH': 13,\n",
       "         'CHEMENG': 13,\n",
       "         'ASNAMST': 12,\n",
       "         'FRENLANG': 12,\n",
       "         'OSPBER': 12,\n",
       "         'COLLEGE': 12,\n",
       "         'HUMRTS': 11,\n",
       "         'OSPSANTG': 11,\n",
       "         'ORALCOMM': 11,\n",
       "         'FILMPROD': 11,\n",
       "         'OUTDOOR': 11,\n",
       "         'GENE': 11,\n",
       "         'BIOS': 10,\n",
       "         'BIOMEDIN': 10,\n",
       "         'RESPROG': 10,\n",
       "         'CHILATST': 10,\n",
       "         'GSBGEN': 10,\n",
       "         'LIFE': 9,\n",
       "         'OSPKYOTO': 9,\n",
       "         'ARABLANG': 9,\n",
       "         'SOMGEN': 9,\n",
       "         'EPI': 9,\n",
       "         'PEDS': 9,\n",
       "         'ITALLANG': 8,\n",
       "         'JAPAN': 8,\n",
       "         'APPPHYS': 8,\n",
       "         'GLOBAL': 8,\n",
       "         'CHINA': 8,\n",
       "         'EASTASN': 8,\n",
       "         'OB': 8,\n",
       "         'KORLANG': 7,\n",
       "         'BIODS': 7,\n",
       "         'COMPMED': 7,\n",
       "         'STRAMGT': 7,\n",
       "         'DATASCI': 7,\n",
       "         'PATH': 7,\n",
       "         'SURG': 7,\n",
       "         'DLCL': 6,\n",
       "         'GERMAN': 6,\n",
       "         'ITALIC': 6,\n",
       "         'IMMUNOL': 6,\n",
       "         'BUSGEN': 6,\n",
       "         'GERLANG': 6,\n",
       "         'ANES': 6,\n",
       "         'JEWISHST': 6,\n",
       "         'LEAD': 5,\n",
       "         'ENVRES': 5,\n",
       "         'REES': 5,\n",
       "         'ARTSINST': 5,\n",
       "         'MI': 5,\n",
       "         'SINY': 5,\n",
       "         'OSPAUSTL': 5,\n",
       "         'CHPR': 5,\n",
       "         'ROTCARMY': 5,\n",
       "         'HRP': 5,\n",
       "         'HUMCORE': 5,\n",
       "         'SUST': 5,\n",
       "         'OSPHONGK': 4,\n",
       "         'SIW': 4,\n",
       "         'SLE': 4,\n",
       "         'KOREA': 3,\n",
       "         'NBIO': 3,\n",
       "         'NENS': 3,\n",
       "         'ATHLETIC': 3,\n",
       "         'FINANCE': 3,\n",
       "         'ACCT': 3,\n",
       "         'STEMREM': 3,\n",
       "         'RAD': 3,\n",
       "         'ITALIAN': 3,\n",
       "         'SLAVIC': 3,\n",
       "         'SOAR': 2,\n",
       "         'LAWGEN': 2,\n",
       "         'CBIO': 2,\n",
       "         'PORTLANG': 2,\n",
       "         'DBIO': 2,\n",
       "         'MKTG': 2,\n",
       "         'NSUR': 2,\n",
       "         'ORTHO': 2,\n",
       "         'INDE': 2,\n",
       "         'CSB': 2,\n",
       "         'OTOHNS': 2,\n",
       "         'OSPGEN': 2,\n",
       "         'AFRICAST': 2,\n",
       "         'OSPCPTWN': 2,\n",
       "         'EALC': 2,\n",
       "         'LATINAM': 1,\n",
       "         'DERM': 1,\n",
       "         'OIT': 1,\n",
       "         'SBIO': 1,\n",
       "         'OPHT': 1,\n",
       "         'FAMMED': 1,\n",
       "         'MGTECON': 1,\n",
       "         'ROTCAF': 1,\n",
       "         'UROL': 1,\n",
       "         'PAS': 1,\n",
       "         'MLA': 1,\n",
       "         'BIOC': 1,\n",
       "         'NEPR': 1,\n",
       "         'OBGYN': 1,\n",
       "         'MCS': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = []\n",
    "embeddings_list = []\n",
    "titles = []\n",
    "for course in courses:\n",
    "    subject = course_metadata[course]['subject']\n",
    "    title = course_metadata[course]['title']\n",
    "    embeddings_list.append(course_embeddings[course])\n",
    "    subjects.append(subject)\n",
    "    titles.append(title)\n",
    "\n",
    "subjects_counter = Counter(subjects)\n",
    "print(\"Number of unique subjects:\", len(subjects_counter))\n",
    "subjects_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def get_clustering_model(embeddings_list, distance_threshold=0.1, metric='cosine', linkage='average', standardize=False):\n",
    "    \"\"\"\n",
    "    Generate and fit an AgglomerativeClustering model using the given parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings_list (list of arrays): List containing embeddings to be clustered.\n",
    "    - distance_threshold (float, optional): The linkage distance threshold above which clusters won't be merged. Defaults to 0.1.\n",
    "    - metric (str, optional): The distance metric to use for the clustering. Allowed values include 'euclidean', 'l1', 'l2', 'manhattan', 'cosine', and 'precomputed'. Defaults to 'cosine'.\n",
    "    - linkage (str, optional): The linkage criterion to use. The linkage criterion determines which distance to use between sets of observations. Allowed values are 'ward', 'complete', 'average', and 'single'. Defaults to 'average'.\n",
    "    - standardize (bool, optional): Whether to standardize the embeddings before clustering. If set to True, the embeddings are standardized to have a mean of 0 and a standard deviation of 1. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "    - model (AgglomerativeClustering): The trained clustering model with the specified parameters.\n",
    "    - embeddings (numpy array): The embeddings used for clustering. If standardize=True, this will return the standardized embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert list of embeddings to a matrix\n",
    "    embeddings_list = np.vstack(embeddings_list)\n",
    "    \n",
    "    # If standardization is set to True, standardize the embeddings\n",
    "    if standardize:\n",
    "        scaler = StandardScaler()\n",
    "        embeddings_list = scaler.fit_transform(embeddings_list)\n",
    "\n",
    "    # Initialize and configure the AgglomerativeClustering model\n",
    "    model = AgglomerativeClustering(\n",
    "        distance_threshold=distance_threshold,\n",
    "        metric=metric,\n",
    "        n_clusters=None,\n",
    "        linkage=linkage\n",
    "    )\n",
    "\n",
    "    # Fit the model to the embeddings\n",
    "    model.fit(embeddings_list)\n",
    "\n",
    "    return model, embeddings_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = 3\n",
    "linkage = \"average\"\n",
    "metric = 'euclidean'\n",
    "standardize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, embeddings = get_clustering_model(embeddings_list=embeddings_list, \n",
    "                                         distance_threshold=distance_threshold,\n",
    "                                         metric=metric,\n",
    "                                         linkage=linkage,\n",
    "                                         standardize=standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4154\n"
     ]
    }
   ],
   "source": [
    "# Cluster labels\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Course\": courses,\n",
    "    \"subject\" : subjects,\n",
    "    \"Group\" : model.labels_\n",
    "})\n",
    "\n",
    "print(len(model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of\")\n",
    "print(len(set(model.labels_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's do binary search to get a good distance threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_dict = {}\n",
    "metric = 'euclidean' #'cosine'\n",
    "linkage = \"ward\" #\"average\"\n",
    "standardize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_for_optimal_distance(low, high, target_clusters, tolerance=3, max_iter=20, similar_distance_tolerance=1e-5):\n",
    "    \"\"\"\n",
    "    Performs a binary search to find the optimal distance value for agglomerative clustering.\n",
    "    Stores the number of clusters and model for each distance tried in a dictionary.\n",
    "    If a distance is within a 1e-5 delta of a previously calculated distance, it reuses the stored model.\n",
    "\n",
    "    :param low: Lower bound of the distance value.\n",
    "    :param high: Upper bound of the distance value.\n",
    "    :param target_clusters: Target number of clusters to find.\n",
    "    :param tolerance: Tolerance for the difference in the number of clusters.\n",
    "    :param max_iter: Maximum number of iterations to prevent infinite loops.\n",
    "    :return: Optimal distance value along with the model.\n",
    "    \"\"\"\n",
    "    iterations = 0\n",
    "    while low <= high and iterations < max_iter:\n",
    "        mid = round((low + high) / 2.0, 6)\n",
    "        print(f\"{iterations} - Trying:\", mid)\n",
    "        \n",
    "        # Check if the mid value or a close value has been computed before\n",
    "        close_distance = None\n",
    "        for d in distance_dict:\n",
    "            if abs(d - mid) < similar_distance_tolerance:\n",
    "                close_distance = d\n",
    "                break\n",
    "        \n",
    "        if close_distance is not None:\n",
    "            print(\"Using stored model for distance:\", close_distance)\n",
    "            model = distance_dict[close_distance]['model']\n",
    "            num_clusters = distance_dict[close_distance]['num_clusters']\n",
    "        else:\n",
    "            print(\"Calculating model for distance!\")\n",
    "            model, embeddings = get_clustering_model(embeddings_list=embeddings_list, \n",
    "                                                     distance_threshold=mid,\n",
    "                                                     metric=metric,\n",
    "                                                     linkage=linkage,\n",
    "                                                     standardize=standardize)\n",
    "            \n",
    "            num_clusters = len(set(model.labels_))\n",
    "            \n",
    "            # Store the model and number of clusters in the dictionary\n",
    "            distance_dict[mid] = {'model': model, 'num_clusters': num_clusters}\n",
    "        \n",
    "        print(\"Num of clusters:\", num_clusters)\n",
    "        if abs(num_clusters - target_clusters) <= tolerance:\n",
    "            print(\"Found good distance! Num of clusters:\", num_clusters, \"\\nDistance:\", mid, \"\\n\")\n",
    "            return model, mid  # Found a suitable distance\n",
    "        elif num_clusters < target_clusters:\n",
    "            high = mid\n",
    "        else:\n",
    "            low = mid\n",
    "        iterations += 1\n",
    "    return None, None  # Return None if no suitable distance is found within the max iterations\n",
    "\n",
    "# We can now call this function with the user's specified bounds.\n",
    "#model, optimal_distance = binary_search_for_optimal_distance(0.01, 0.3, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Metric = Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Trying: 0.155\n",
      "Calculating model for distance!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cosine was provided as metric. Ward can only work with euclidean distances.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\CS224W-Final-Project\\embedding_visualization.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# We can now call this function with the user's specified bounds.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model, optimal_distance \u001b[39m=\u001b[39m binary_search_for_optimal_distance(\u001b[39m0.01\u001b[39;49m, \u001b[39m0.3\u001b[39;49m, \u001b[39m30\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Projects\\CS224W-Final-Project\\embedding_visualization.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCalculating model for distance!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     model, embeddings \u001b[39m=\u001b[39m get_clustering_model(embeddings_list\u001b[39m=\u001b[39;49membeddings_list, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                                              distance_threshold\u001b[39m=\u001b[39;49mmid,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                                              metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                                              linkage\u001b[39m=\u001b[39;49mlinkage,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                                              standardize\u001b[39m=\u001b[39;49mstandardize)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     num_clusters \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(model\u001b[39m.\u001b[39mlabels_))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m# Store the model and number of clusters in the dictionary\u001b[39;00m\n",
      "\u001b[1;32mc:\\Projects\\CS224W-Final-Project\\embedding_visualization.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m model \u001b[39m=\u001b[39m AgglomerativeClustering(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     distance_threshold\u001b[39m=\u001b[39mdistance_threshold,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     metric\u001b[39m=\u001b[39mmetric,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     n_clusters\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     linkage\u001b[39m=\u001b[39mlinkage\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Fit the model to the embeddings\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(embeddings_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X22sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, embeddings_list\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ReactGenie\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ReactGenie\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:978\u001b[0m, in \u001b[0;36mAgglomerativeClustering.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the hierarchical clustering from features, or distance matrix.\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \n\u001b[0;32m    962\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[39m    Returns the fitted instance.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    977\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, ensure_min_samples\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 978\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n",
      "File \u001b[1;32mc:\\Users\\chris\\anaconda3\\envs\\ReactGenie\\Lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:1029\u001b[0m, in \u001b[0;36mAgglomerativeClustering._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1025\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcompute_full_tree must be True if distance_threshold is set.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1026\u001b[0m     )\n\u001b[0;32m   1028\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinkage \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mward\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1030\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric\u001b[39m}\u001b[39;00m\u001b[39m was provided as metric. Ward can only \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1031\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwork with euclidean distances.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1032\u001b[0m     )\n\u001b[0;32m   1034\u001b[0m tree_builder \u001b[39m=\u001b[39m _TREE_BUILDERS[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinkage]\n\u001b[0;32m   1036\u001b[0m connectivity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnectivity\n",
      "\u001b[1;31mValueError\u001b[0m: cosine was provided as metric. Ward can only work with euclidean distances."
     ]
    }
   ],
   "source": [
    "# We can now call this function with the user's specified bounds.\n",
    "model, optimal_distance = binary_search_for_optimal_distance(0.01, 0.3, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Metric = Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Trying: 1.5005\n",
      "Calculating model for distance!\n",
      "Num of clusters: 35\n",
      "1 - Trying: 2.25025\n",
      "Calculating model for distance!\n",
      "Num of clusters: 16\n",
      "2 - Trying: 1.875375\n",
      "Calculating model for distance!\n",
      "Num of clusters: 24\n",
      "3 - Trying: 2.062812\n",
      "Calculating model for distance!\n",
      "Num of clusters: 20\n",
      "Found good distance! Num of clusters: 20 \n",
      "Distance: 2.062812 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can now call this function with the user's specified bounds.\n",
    "model, optimal_distance = binary_search_for_optimal_distance(0.001, 3, 20, tolerance=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 2.062812; \tLinkage: ward; \tMetric: euclidean; \n",
      "Clusters: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Group\n",
       "0     281\n",
       "1     536\n",
       "2     407\n",
       "3     174\n",
       "4     165\n",
       "5     281\n",
       "6     243\n",
       "7     238\n",
       "8     269\n",
       "9      78\n",
       "10    128\n",
       "11    195\n",
       "12    191\n",
       "13    185\n",
       "14     25\n",
       "15    171\n",
       "16    184\n",
       "17    187\n",
       "18    156\n",
       "19     60\n",
       "Name: Course, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster labels\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Course\": courses,\n",
    "    \"Subject\" : subjects,\n",
    "    \"Title\" : titles,\n",
    "    \"Group\" : model.labels_\n",
    "})\n",
    "print(f\"Distance: {optimal_distance}; \\tLinkage: {linkage}; \\tMetric: {metric}; \\nClusters: {model.n_clusters_}\")\n",
    "df.groupby(\"Group\").Course.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>UAR101P</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Ujamaa (Redwood)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>UAR194A</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101 and Transfer 101: Leader Training</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>UAR101U</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Castaño (Wisteria)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>UAR101A</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Burbank (Aspen)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>UAR101D</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Larkin (Aspen)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>UAR101L</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Schiff (Magnolia)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>UAR101H</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Rinconada (Hyperion)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>UAR101T</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Okada (Sequoia)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>UAR101S</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Junipero (Sequoia)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>UAR101N</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Muwekma-Tah-Ruk (Olive)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>UAR101O</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: West Florence Moore - Mirlo (Olive)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>UAR101E</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Branner (Ginkgo)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>UAR101Q</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: West Lagunita - Eucalipto &amp; Granada...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>UAR101V</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Lantana (Wisteria)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>UAR101B</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Casa Zapata (Aspen)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>UAR201</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Transfer 101</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>UAR101F</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Crothers (Ginkgo)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>UAR101J</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Potter (Magnolia)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>UAR101I</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Soto (Hyperion)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>UAR101K</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Robinson (Magnolia)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3476</th>\n",
       "      <td>UAR101R</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Cedro (Sequoia)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>UAR101M</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: East Florence Moore - Alondra &amp; Car...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>UAR101G</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Otero (Hyperion)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>UAR194B</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101 and Transfer 101: Curriculum Training</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>UAR101C</td>\n",
       "      <td>UAR</td>\n",
       "      <td>Frosh 101: Donner (Aspen)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Course Subject                                              Title  \\\n",
       "299   UAR101P     UAR                        Frosh 101: Ujamaa (Redwood)   \n",
       "421   UAR194A     UAR        Frosh 101 and Transfer 101: Leader Training   \n",
       "464   UAR101U     UAR                      Frosh 101: Castaño (Wisteria)   \n",
       "578   UAR101A     UAR                         Frosh 101: Burbank (Aspen)   \n",
       "689   UAR101D     UAR                          Frosh 101: Larkin (Aspen)   \n",
       "1001  UAR101L     UAR                       Frosh 101: Schiff (Magnolia)   \n",
       "1248  UAR101H     UAR                    Frosh 101: Rinconada (Hyperion)   \n",
       "1342  UAR101T     UAR                         Frosh 101: Okada (Sequoia)   \n",
       "1428  UAR101S     UAR                      Frosh 101: Junipero (Sequoia)   \n",
       "1726  UAR101N     UAR                 Frosh 101: Muwekma-Tah-Ruk (Olive)   \n",
       "2125  UAR101O     UAR     Frosh 101: West Florence Moore - Mirlo (Olive)   \n",
       "2157  UAR101E     UAR                        Frosh 101: Branner (Ginkgo)   \n",
       "2318  UAR101Q     UAR  Frosh 101: West Lagunita - Eucalipto & Granada...   \n",
       "2478  UAR101V     UAR                      Frosh 101: Lantana (Wisteria)   \n",
       "2566  UAR101B     UAR                     Frosh 101: Casa Zapata (Aspen)   \n",
       "2637   UAR201     UAR                                       Transfer 101   \n",
       "2656  UAR101F     UAR                       Frosh 101: Crothers (Ginkgo)   \n",
       "3103  UAR101J     UAR                       Frosh 101: Potter (Magnolia)   \n",
       "3337  UAR101I     UAR                         Frosh 101: Soto (Hyperion)   \n",
       "3469  UAR101K     UAR                     Frosh 101: Robinson (Magnolia)   \n",
       "3476  UAR101R     UAR                         Frosh 101: Cedro (Sequoia)   \n",
       "3617  UAR101M     UAR  Frosh 101: East Florence Moore - Alondra & Car...   \n",
       "3787  UAR101G     UAR                        Frosh 101: Otero (Hyperion)   \n",
       "3859  UAR194B     UAR    Frosh 101 and Transfer 101: Curriculum Training   \n",
       "3981  UAR101C     UAR                          Frosh 101: Donner (Aspen)   \n",
       "\n",
       "      Group  \n",
       "299      14  \n",
       "421      14  \n",
       "464      14  \n",
       "578      14  \n",
       "689      14  \n",
       "1001     14  \n",
       "1248     14  \n",
       "1342     14  \n",
       "1428     14  \n",
       "1726     14  \n",
       "2125     14  \n",
       "2157     14  \n",
       "2318     14  \n",
       "2478     14  \n",
       "2566     14  \n",
       "2637     14  \n",
       "2656     14  \n",
       "3103     14  \n",
       "3337     14  \n",
       "3469     14  \n",
       "3476     14  \n",
       "3617     14  \n",
       "3787     14  \n",
       "3859     14  \n",
       "3981     14  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.Group == 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAD ATTEMPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Now, let's export each group to a separate sheet in an Excel workbook\n",
    "with pd.ExcelWriter('groups.xlsx') as writer:\n",
    "    for group in sorted(df['Group'].unique()):\n",
    "        group_df = df[df['Group'] == group]\n",
    "        group_df.to_excel(writer, sheet_name=f'Group_{group}', index=False)\n",
    "\n",
    "    # Additionally, create a single sheet with all entries, separated by groups with 4 empty rows apart\n",
    "    all_groups_df = pd.DataFrame()\n",
    "    for group in sorted(df['Group'].unique()):\n",
    "        group_df = df[df['Group'] == group]\n",
    "        all_groups_df = all_groups_df.append(group_df, ignore_index=True)\n",
    "        # Add 4 empty rows after each group\n",
    "        all_groups_df = all_groups_df.append(pd.DataFrame([['']*len(df.columns)] * 4, columns=df.columns), ignore_index=True)\n",
    "\n",
    "    all_groups_df.to_excel(writer, sheet_name='All_Groups', index=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting an excel file containing each course by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure you have your DataFrame 'df' loaded correctly here\n",
    "# For example:\n",
    "# df = pd.read_csv('your_data.csv')  # or however you are creating your DataFrame\n",
    "\n",
    "# Now, let's export each group to a separate sheet in an Excel workbook\n",
    "with pd.ExcelWriter('groups.xlsx') as writer:\n",
    "    for group in sorted(df['Group'].unique()):\n",
    "        group_df = df[df['Group'] == group]\n",
    "        group_df.to_excel(writer, sheet_name=f'Group_{group}', index=False)\n",
    "\n",
    "    # Additionally, create a single sheet with all entries, separated by groups with 4 empty rows apart\n",
    "    all_groups_df = pd.DataFrame()\n",
    "    for group in sorted(df['Group'].unique()):\n",
    "        group_df = df[df['Group'] == group]\n",
    "        all_groups_df = pd.concat([all_groups_df, group_df], ignore_index=True)\n",
    "        # Add 4 empty rows after each group\n",
    "        empty_rows = pd.DataFrame([['']*len(df.columns)] * 4, columns=df.columns)\n",
    "        all_groups_df = pd.concat([all_groups_df, empty_rows], ignore_index=True)\n",
    "\n",
    "    all_groups_df.to_excel(writer, sheet_name='All_Groups', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\CS224W-Final-Project\\embedding_visualization.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/CS224W-Final-Project/embedding_visualization.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mrepr\u001b[39;49m(df)\u001b[39m.\u001b[39;49mgroupby\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "repr(df).groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency by Cluster:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Group\n",
       "0     134\n",
       "1      95\n",
       "2     120\n",
       "3     103\n",
       "4      85\n",
       "5      86\n",
       "6     135\n",
       "7      63\n",
       "8      83\n",
       "9      91\n",
       "10    128\n",
       "11     98\n",
       "12    107\n",
       "13    117\n",
       "14     65\n",
       "15     77\n",
       "16     73\n",
       "17     88\n",
       "18     65\n",
       "19     78\n",
       "20     29\n",
       "21     57\n",
       "22     76\n",
       "23     93\n",
       "24     52\n",
       "25     70\n",
       "26     87\n",
       "27     45\n",
       "28    113\n",
       "29     75\n",
       "30     75\n",
       "31     72\n",
       "32     46\n",
       "33     83\n",
       "34     40\n",
       "35     96\n",
       "36     28\n",
       "37     65\n",
       "38     73\n",
       "39     37\n",
       "40     60\n",
       "41     60\n",
       "42     47\n",
       "43     34\n",
       "44     61\n",
       "45     68\n",
       "46     44\n",
       "47     38\n",
       "48     39\n",
       "49     10\n",
       "50     67\n",
       "51     59\n",
       "52     27\n",
       "53     67\n",
       "54     22\n",
       "55     36\n",
       "56     34\n",
       "57     55\n",
       "58     48\n",
       "59     25\n",
       "60     50\n",
       "Name: Course, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Frequency by Cluster:\")\n",
    "df.groupby(\"Group\").Course.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for course in courses:\n",
    "    embeddings[course]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReactGenie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
