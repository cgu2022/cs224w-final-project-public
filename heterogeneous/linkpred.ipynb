{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneous Graph Neural Network for Link Prediction\n",
    "This notebook demonstrates the implementation of a Graph Neural Network (GNN) for link prediction in heterogeneous networks. We use PyTorch and PyTorch Geometric for building and training the model. The notebook is structured to provide clarity and a step-by-step approach to the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx \n",
    "import sklearn.metrics as metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "from deepsnap.hetero_graph import HeteroGraph\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from deepsnap.batch import Batch\n",
    "from deepsnap.hetero_gnn import (\n",
    "    HeteroSAGEConv,\n",
    "    HeteroConv,\n",
    "    forward_op\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argument Parsing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_parse():\n",
    "    parser = argparse.ArgumentParser(description='Link pred arguments.')\n",
    "    parser.add_argument('--device', type=str,\n",
    "                        help='CPU / GPU device.')\n",
    "    parser.add_argument('--data_path', type=str,\n",
    "                        help='Path to wordnet nx gpickle file.')\n",
    "    parser.add_argument('--epochs', type=int,\n",
    "                        help='Number of epochs to train.')\n",
    "    parser.add_argument('--mode', type=str,\n",
    "                        help='Link prediction mode. Disjoint or all.')\n",
    "    parser.add_argument('--edge_message_ratio', type=float,\n",
    "                        help='Ratio of edges used for message-passing (only in disjoint mode).')\n",
    "    parser.add_argument('--hidden_dim', type=int,\n",
    "                        help='Hidden dimension of GNN.')\n",
    "    parser.add_argument('--lr', type=float,\n",
    "                        help='The learning rate.')\n",
    "    parser.add_argument('--weight_decay', type=float,\n",
    "                        help='Weight decay.')\n",
    "\n",
    "    parser.set_defaults(\n",
    "            device='cuda:0',\n",
    "            data_path='data/oncourse.pkl',\n",
    "            epochs=200, # originally 200\n",
    "            mode='disjoint',\n",
    "            edge_message_ratio=0.8,\n",
    "            hidden_dim=32,\n",
    "            lr=0.01,\n",
    "            weight_decay=1e-4,\n",
    "    )\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WN_transform(G, num_edge_types, input_dim=5):\n",
    "    # Function to transform the data\n",
    "    H = nx.MultiDiGraph()\n",
    "    for node in G.nodes():\n",
    "        #node_label=G.nodes[node]['node_type']\n",
    "        H.add_node(node, node_type='n1', node_feature=torch.ones(input_dim))\n",
    "    for u, v, edge_key in G.edges:\n",
    "        l = G[u][v][edge_key]['e_label']\n",
    "        e_feat = torch.zeros(num_edge_types)\n",
    "        e_feat[l] = 1.\n",
    "        H.add_edge(u, v, edge_feature=e_feat, edge_type=str(l.item()))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeteroGNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, conv1, conv2, hetero, hidden_size, node_embed_size=32):\n",
    "        super(HeteroGNN, self).__init__()\n",
    "        \n",
    "        self.convs1 = HeteroConv(conv1) # Wrap the heterogeneous GNN layers\n",
    "        self.convs2 = HeteroConv(conv2)\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        self.bns1 = nn.ModuleDict()\n",
    "        self.bns2 = nn.ModuleDict()\n",
    "        self.relus1 = nn.ModuleDict()\n",
    "        # self.relus2 = nn.ModuleDict()\n",
    "        # self.post_mps = nn.ModuleDict()\n",
    "        self.edge_mlp = nn.ModuleDict()\n",
    "\n",
    "        for node_type in hetero.node_types:\n",
    "            self.bns1[node_type] = torch.nn.BatchNorm1d(hidden_size)\n",
    "            self.bns2[node_type] = torch.nn.BatchNorm1d(hidden_size)\n",
    "            self.relus1[node_type] = nn.LeakyReLU()\n",
    "            # self.relus2[node_type] = nn.LeakyReLU()\n",
    "        \n",
    "        \n",
    "        for edge_type in hetero.edge_types:\n",
    "            self.edge_mlp[edge_type] = nn.Linear(node_embed_size * 2, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        '''\n",
    "        node_feature: dictionary of {node type (e.g. 'user') : tensor of all embeddings of that node type (# num nodes, 32)}\n",
    "        edge_index: dictionary of {edge type (e.g. ('user', '0', 'course')) : tensor of all edges (2, # edges)}\n",
    "        edge_label_index: same structure as edge_index. this indicates the edges to be evaluated on\n",
    "        '''\n",
    "        if type(data) == Batch:\n",
    "            x = data.node_feature\n",
    "            edge_index = data.edge_index\n",
    "            edge_label_index = data.edge_label_index  # dictionary \n",
    "        elif type(data) == dict:\n",
    "            x = data['node_feature']\n",
    "            edge_index = data['edge_index']\n",
    "            edge_label_index = data['edge_label_index']\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unknown data format\")\n",
    "        \n",
    "        x = self.convs1(x, edge_index)\n",
    "        x = forward_op(x, self.bns1)\n",
    "        x = forward_op(x, self.relus1)\n",
    "        x = self.convs2(x, edge_index)\n",
    "        x = forward_op(x, self.bns2)\n",
    "\n",
    "        pred = {}\n",
    "        for message_type in edge_label_index:\n",
    "            nodes_first = torch.index_select(x[message_type[0]], 0, edge_label_index[message_type][0,:].long())  # shape [10134, 32]\n",
    "            nodes_second = torch.index_select(x[message_type[2]], 0, edge_label_index[message_type][1,:].long())\n",
    "            pred[message_type] = self.edge_mlp[message_type[1]](torch.cat((nodes_first, nodes_second), dim=-1)).reshape(-1) # shape [10134]\n",
    "        return pred\n",
    "\n",
    "    def loss(self, pred, y):\n",
    "        loss = 0\n",
    "        for key in pred:\n",
    "            p = torch.sigmoid(pred[key])\n",
    "            loss += self.loss_fn(p, y[key].type(pred[key].dtype))\n",
    "        return loss\n",
    "    \n",
    "    def bpr_loss(self, pred, y):\n",
    "        loss = 0\n",
    "        epsilon = 1e-7\n",
    "        for key in pred:\n",
    "            dim = pred[key].shape[0]\n",
    "            assert dim % 2 == 0\n",
    "            assert torch.equal(y[key][:dim//2], torch.ones_like(y[key][:dim//2]))\n",
    "            assert torch.equal(y[key][dim//2:], torch.zeros_like(y[key][dim//2:]))\n",
    "            p = pred[key]\n",
    "            positive = p[:dim//2]\n",
    "            negative = p[dim//2:]\n",
    "            loss += -torch.sum(torch.log(torch.sigmoid(positive - negative) + epsilon))\n",
    "        return loss\n",
    "\n",
    "def generate_2convs_link_pred_layers(hete, conv, hidden_size):\n",
    "    convs1 = {}\n",
    "    convs2 = {}\n",
    "    for message_type in hete.message_types:\n",
    "        n_type = message_type[0]\n",
    "        s_type = message_type[2]\n",
    "        n_feat_dim = hete.num_node_features(n_type)\n",
    "        s_feat_dim = hete.num_node_features(s_type)\n",
    "        convs1[message_type] = conv(n_feat_dim, hidden_size, s_feat_dim)\n",
    "        convs2[message_type] = conv(hidden_size, hidden_size, hidden_size)\n",
    "    return convs1, convs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negative sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_negative_samples(batch):\n",
    "    positive_edges = {}\n",
    "    for message_type in batch.edge_label_index:\n",
    "        positive_edges[message_type] = set()\n",
    "        for edge in batch.edge_index[message_type].T:\n",
    "            positive_edges[message_type].add((edge[0].item(), edge[1].item()))\n",
    "        for edge in batch.edge_label_index[message_type].T:\n",
    "            positive_edges[message_type].add((edge[0].item(), edge[1].item()))\n",
    "            \n",
    "    new_edge_label_index = {}\n",
    "    new_labels = {}\n",
    "    for message_type in batch.edge_label_index:\n",
    "        num_users = batch.node_feature[message_type[0]].shape[0]\n",
    "        num_courses = batch.node_feature[message_type[2]].shape[1]\n",
    "        \n",
    "        positive_indices = torch.nonzero(batch.edge_label[message_type]).squeeze()\n",
    "        num_positive_samples = positive_indices.shape[0]\n",
    "        positive_edge_index = batch.edge_label_index[message_type][:, positive_indices]\n",
    "        \n",
    "        new_edge_label_index[message_type] = torch.cat((positive_edge_index, torch.zeros_like(positive_edge_index)), dim=-1)\n",
    "        for i in range(num_positive_samples, 2*num_positive_samples):  # use the same number of negative edges as positive edges\n",
    "            user, random_course = positive_edge_index[0][i-num_positive_samples], -1\n",
    "            while True:\n",
    "                random_course = random.randrange(0, num_courses)\n",
    "                if (user, random_course) not in positive_edges[message_type]:\n",
    "                    break\n",
    "            new_edge_label_index[message_type][0][i] = user\n",
    "            new_edge_label_index[message_type][1][i] = random_course\n",
    "        new_labels[message_type] = torch.cat((batch.edge_label[message_type][positive_indices], torch.zeros_like(batch.edge_label[message_type][positive_indices])))\n",
    "    \n",
    "    new_batch = {\n",
    "        'node_feature': batch.node_feature,\n",
    "        'edge_index': batch.edge_index,\n",
    "        'edge_label_index': new_edge_label_index\n",
    "    }\n",
    "    \n",
    "    return new_batch, new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders, optimizer, args):\n",
    "    val_max = 0\n",
    "    best_model = model\n",
    "    t_accu = []\n",
    "    v_accu = []\n",
    "    e_accu = []\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        for iter_i, batch in enumerate(dataloaders['train']):\n",
    "            batch.to(args.device)\n",
    "            new_batch, new_labels = add_negative_samples(batch)\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(new_batch)\n",
    "            loss = model.bpr_loss(pred, new_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            log = 'Epoch: {:03d}, Train loss: {:.4f}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "            accs = test_metrics(model, dataloaders, args)\n",
    "            t_accu.append(accs['train'])\n",
    "            v_accu.append(accs['val'])\n",
    "            e_accu.append(accs['test'])\n",
    "\n",
    "            print(log.format(epoch, loss.item(), accs['train'], accs['val'], accs['test']))\n",
    "            if val_max < accs['val']:\n",
    "                val_max = accs['val']\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "    log = 'Best: Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    accs = test(best_model, dataloaders, args)\n",
    "    print(log.format(accs['train'], accs['val'], accs['test']))\n",
    "    torch.save(best_model, \"model/hetero.pt\")\n",
    "\n",
    "    return t_accu, v_accu, e_accu\n",
    "\n",
    "\n",
    "def test(model, dataloaders, args):\n",
    "    model.eval()\n",
    "    accs = {}\n",
    "    for mode, dataloader in dataloaders.items():\n",
    "        acc = 0\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            num = 0\n",
    "            batch.to(args.device)\n",
    "            pred = model(batch)\n",
    "            for key in pred:\n",
    "                p = torch.sigmoid(pred[key]).cpu().detach().numpy()\n",
    "                pred_label = np.zeros_like(p, dtype=np.int64)\n",
    "                pred_label[np.where(p > 0.5)[0]] = 1\n",
    "                pred_label[np.where(p <= 0.5)[0]] = 0\n",
    "                acc += np.sum(pred_label == batch.edge_label[key].cpu().numpy())\n",
    "                num += len(pred_label)\n",
    "        accs[mode] = acc / num\n",
    "    return accs\n",
    "\n",
    "\n",
    "def test_metrics(model, dataloaders, args):\n",
    "    model.eval()\n",
    "    recalls = {}\n",
    "    RECALL_K = 20\n",
    "    for mode, dataloader in dataloaders.items():\n",
    "        recall = 0\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            assert i == 0  # only works if there's only one batch\n",
    "            batch.to(args.device)\n",
    "            num_users = batch.node_feature['user'].shape[0]\n",
    "            num_effective_users = num_users\n",
    "            num_courses = batch.node_feature['course'].shape[0]\n",
    "            all_pairs_index = torch.Tensor(2, num_users * num_courses).to(args.device)\n",
    "            \n",
    "            positive_edges = set()\n",
    "            num_positive_edges = torch.argmin(batch.edge_label[('user', '0', 'course')]).item()\n",
    "            user_num_edges = [0 for _ in range(num_users)]\n",
    "            \n",
    "            for j in range(num_positive_edges):\n",
    "                user_ind = batch.edge_label_index[('user', '0', 'course')][0, j].item()\n",
    "                course_ind = batch.edge_label_index[('user', '0', 'course')][1, j].item()\n",
    "                if ((user_ind, course_ind)) not in positive_edges:\n",
    "                    positive_edges.add((user_ind, course_ind))\n",
    "                    user_num_edges[user_ind] += 1\n",
    "                \n",
    "            user_indices, course_indices = torch.meshgrid(\n",
    "                torch.arange(num_users, device=args.device), \n",
    "                torch.arange(num_courses, device=args.device)\n",
    "            )\n",
    "            all_pairs_index = torch.stack([user_indices.flatten(), course_indices.flatten()]).to(args.device)\n",
    "            \n",
    "            all_pairs = {\n",
    "                'node_feature': batch.node_feature,\n",
    "                'edge_index': batch.edge_index,\n",
    "                'edge_label_index': {\n",
    "                    ('user', '0', 'course'): all_pairs_index\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            pred = model(all_pairs)\n",
    "            for j, key in enumerate(pred):\n",
    "                assert j == 0  # should only be one type of edge, namely, ('user', '0', 'course')\n",
    "                p = torch.sigmoid(pred[key]).cpu().detach()\n",
    "                \n",
    "                ## convert to matrix\n",
    "                p_matrix = p.reshape((num_users, num_courses))\n",
    "                    \n",
    "                ## exclude edges already in the edge_index\n",
    "                for edge in batch.edge_index[('user', '0', 'course')].T:\n",
    "                    if (edge[0].item(), edge[1].item()) in positive_edges: continue\n",
    "                    p_matrix[edge[0].item(), edge[1].item()] = -(1 << 10)  # set to large negative value\n",
    "                \n",
    "                ### compute recall@K for each user\n",
    "                _, top_k_indices = torch.topk(p_matrix, k=RECALL_K)\n",
    "                for user in range(num_users):\n",
    "                    if user_num_edges[user] == 0:\n",
    "                        num_effective_users -= 1\n",
    "                        continue\n",
    "                    num_correct = 0\n",
    "                    for rec in top_k_indices[user]:\n",
    "                        if (user, rec.item()) in positive_edges: num_correct += 1\n",
    "                    recall_user = num_correct / user_num_edges[user]\n",
    "                    assert recall_user <= 1\n",
    "                    recall += recall_user\n",
    "        recalls[mode] = recall / num_effective_users\n",
    "    return recalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = arg_parse()\n",
    "\n",
    "edge_train_mode = args.mode\n",
    "print('edge train mode: {}'.format(edge_train_mode))\n",
    "\n",
    "with open(args.data_path, 'rb') as f:\n",
    "    G = pickle.load(f)\n",
    "print(f'dataset: {args.data_path}')\n",
    "print(G.number_of_nodes(), G.number_of_edges())\n",
    "\n",
    "# find num edge types\n",
    "max_label = 0\n",
    "labels = []\n",
    "for u, v, edge_key in G.edges:\n",
    "    l = G[u][v][edge_key]['e_label']\n",
    "    if not l in labels:\n",
    "        labels.append(l)\n",
    "# labels are consecutive (0-17)\n",
    "num_edge_types = len(labels)\n",
    "\n",
    "H = WN_transform(G, num_edge_types, args.node_embedding_dim)\n",
    "hetero = HeteroGraph(H)\n",
    "\n",
    "if edge_train_mode == \"disjoint\":\n",
    "    dataset = GraphDataset(\n",
    "        [hetero],\n",
    "        task='link_pred',\n",
    "        edge_train_mode=edge_train_mode,\n",
    "        edge_message_ratio=args.edge_message_ratio\n",
    "    )\n",
    "else:\n",
    "    dataset = GraphDataset(\n",
    "        [hetero],\n",
    "        task='link_pred',\n",
    "        edge_train_mode=edge_train_mode,\n",
    "    )\n",
    "\n",
    "dataset_train, dataset_val, dataset_test = dataset.split(\n",
    "    transductive=True, split_ratio=[0.8, 0.1, 0.1]\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset_train, collate_fn=Batch.collate(), batch_size=1\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset_val, collate_fn=Batch.collate(), batch_size=1\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset_test, collate_fn=Batch.collate(), batch_size=1\n",
    ")\n",
    "dataloaders = {\n",
    "    'train': train_loader, 'val': val_loader, 'test': test_loader\n",
    "}\n",
    "\n",
    "hidden_size = args.hidden_dim\n",
    "conv1, conv2 = generate_2convs_link_pred_layers(hetero, HeteroSAGEConv, hidden_size)\n",
    "model = HeteroGNN(conv1, conv2, hetero, hidden_size, args.node_embedding_dim).to(args.device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
    ")\n",
    "\n",
    "t_accu, v_accu, e_accu = train(model, dataloaders, optimizer, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReactGenie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
